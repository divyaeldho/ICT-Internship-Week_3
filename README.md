 Project Overview

This project implements an automated system to analyse long-duration YouTube videos and extract meaningful conversational moments such as agreement, disagreement, and questionâ€“answer interactions.

The system follows a hybrid AI-based approach, combining multi-stage speech transcription with semantic analysis and rule-based logic. It is designed to handle long-form content reliably and reduce the need for manual video review.

 Key Objectives

Analyse long YouTube videos automatically

Convert speech into clean, structured text

Identify semantically meaningful conversational moments

Extract and categorise relevant video clips

Provide a reusable and scalable analysis pipeline

 Approach Overview

The project uses a hybrid processing strategy:

Speech-to-Text API for raw speech-to-text conversion

Whisper model for transcription refinement

Text cleaning and normalization for semantic readiness

Semantic similarity + rule-based logic for moment classification

FFmpeg-based clipping for automated video segment extraction

This approach improves both transcription quality and semantic accuracy.
